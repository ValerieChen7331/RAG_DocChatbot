# ğŸ“Š æ¨¡å‹å›ç­”æº–ç¢ºç‡ - æ¸¬è©¦æ¨¡çµ„ï¼ˆEvaluation Moduleï¼‰

æœ¬æ¨¡çµ„ç‚ºä¸»å°ˆæ¡ˆã€ŒRAG æ–‡ä»¶æª¢ç´¢èŠå¤©æ©Ÿå™¨äººã€çš„å»¶ä¼¸æ¸¬è©¦å·¥å…·ï¼Œæ—¨åœ¨è‡ªå‹•åŒ–ç”¢ç”Ÿå•ç­”è³‡æ–™é›†ã€åŸ·è¡Œä¸åŒèªè¨€æ¨¡å‹çš„å›ç­”ä»»å‹™ï¼Œä¸¦é‡åŒ–å…¶æº–ç¢ºç‡èˆ‡ç›¸ä¼¼åº¦è¡¨ç¾ã€‚

---

## ğŸ¯ åŠŸèƒ½ç›®æ¨™

- å¾æ–‡ä»¶è‡ªå‹•ç”¢å‡ºå•ç­”è³‡æ–™é›†
- å‘¼å«ä¸åŒ LLM æ¨¡å‹é€²è¡Œå›ç­”ï¼ˆæ”¯æ´å…§éƒ¨æˆ–å¤–éƒ¨ APIï¼‰
- è©•ä¼°æ¨¡å‹å›ç­”èˆ‡æ¨™æº–ç­”æ¡ˆçš„ç›¸ä¼¼åº¦
- åŒ¯å‡ºçµæœ CSVï¼Œä¾›å¾ŒçºŒåˆ†æèˆ‡å ±è¡¨ä½¿ç”¨

---
## ğŸ“Š æ¸¬è©¦çµæœï¼ˆ2025/04/22ï¼‰  
> è©•ä¼°æ¨¡å‹ï¼š`Gemma3_27b`
- `Gemma3_27b` åœ¨ä¸€è‡´æ€§èˆ‡ç©©å®šæ€§è¡¨ç¾æœ€ä½³ï¼Œå¹³å‡å¾—åˆ†æœ€é«˜ã€‚
- `Deepseek_14b_QwenDistill` è¼•é‡ã€æ•ˆç‡æœ€é«˜ã€‚
- `QWQ_32b` æ¨ç†æ¨¡å‹ï¼Œèƒ½å›ç­”è¤‡é›œå•é¡Œ(å› æœæ¨ç†)ï¼Œä½†æœ‰æ™‚æœƒæƒ³å¤ªå¤šã€æ•ˆç‡æ…¢ã€‚

| No.  | LLM                          | Test1 | Test2 | Test3 | Avg.  |
|------|------------------------------|-------|-------|-------|-------|
| â­ 1 | Gemma3_27b                   | 38    | 37    | 38    | 37.7  |
| â­ 2  | Deepseek_14b_QwenDistill     | 39    | 37    | 36    | 37.3  |
| â­ 3  | Gemma2_27b                   | 36    | 38    | 38    | 37.3  |
| 4    | QWQ_32b                      | 39    | 36    | 36    | 37.0  |
| 5    | Deepseek_7b                  | 38    | 33    | 35    | 35.3  |
| 6    | Phi4_14b                     | 33    | 35    | 36    | 34.7  |
| 7    | Gemma3_4b                    | 33    | 33    | 34    | 33.3  |
| 8    | Taiwan_LLaMA3_8b_Instruct    | 33    | 33    | 31    | 32.3  |
| 9    | Mistral_7b_Instruct          | 33    | 29    | 33    | 31.7  |
| 10   | LLaMA3_2_Latest              | 28    | 33    | 31    | 30.7  |


## âš™ï¸ åŸ·è¡Œæ­¥é©Ÿ

### ğŸ” ä¸€éµå…¨æµç¨‹
```bash
python evaluation/run_llm_evaluation.py
```

### ğŸ§ª åˆ†æ­¥åŸ·è¡Œï¼ˆå¯æ­é… import å‘¼å«ï¼‰
```python
from evaluation import run_llm_evaluation

# Step 1ï¼šå¾ DB åŒ¯å‡º QA CSVï¼ˆå¦‚æœªè¨»è§£ï¼‰
run_llm_evaluation.run_step1_export()

# Step 2ï¼šå°å¤šå€‹æ¨¡å‹ç”¢ç”Ÿå›ç­”
run_llm_evaluation.run_step2_generate_answers()

# Step 3ï¼šåŸ·è¡Œæ¨¡å‹å›ç­”è©•ä¼°èˆ‡æ¯”å°
run_llm_evaluation.run_step3_evaluate_answers()
```

---
## ğŸ“‚ å°ˆæ¡ˆçµæ§‹

```
ğŸ“‚ evaluation/                         # æ¨¡å‹å›ç­”è©•ä¼°æ¨¡çµ„ï¼ˆæœ¬æ¨¡çµ„ä¸»è¦å·¥ä½œç›®éŒ„ï¼‰  
â”œâ”€â”€ ğŸ“¦ run_llm_evaluation.py           # ğŸ“Œ ä¸»æµç¨‹å…¥å£ï¼ŒåŸ·è¡Œã€ŒåŒ¯å‡ºã€ç”Ÿæˆã€è©•ä¼°ã€ä¸‰éšæ®µ  
â”œâ”€â”€ ğŸ“¦ export_data.py                  # åŒ¯å‡º DB ä¸­ chunks èˆ‡çµæœ  
â”œâ”€â”€ ğŸ“¦ gen_qa.py                       # å¾ chunks è‡ªå‹•ç”¢ç”Ÿå•ç­”é…å°è³‡æ–™  
â”œâ”€â”€ ğŸ“¦ eval_answer.py                  # ä½¿ç”¨è©•å¯©æ¨¡å‹è©•ä¼°å›ç­”æ­£ç¢ºæ€§  
  
ğŸ“‚ apis/  
â”œâ”€â”€ ğŸ“¦ llm_api.py                      # ç®¡ç†æ‰€æœ‰å¯ç”¨ LLM æ¨¡å‹ï¼ˆå…§éƒ¨ / å¤–éƒ¨ APIï¼‰  
  
ğŸ“‚ mockdata/                           # ğŸ”§ æ¸¬è©¦è¼¸å‡ºè³‡æ–™å¤¾ï¼ˆå«æ¯æ¨¡å‹å›ç­”èˆ‡è©•ä¼°çµæœï¼‰  
â”œâ”€â”€ ğŸ“œ QAData_retrievedContent.csv     # å¾ DB åŒ¯å‡ºçš„åŸå§‹ QA è³‡æ–™  
â”œâ”€â”€ ğŸ“œ QAData_goldenChunk.csv          # é»ƒé‡‘æ¨™æº–ç­”æ¡ˆ QA è³‡æ–™  
â”œâ”€â”€ ğŸ“‚ {æ¨¡å‹åç¨±}/  
â”‚   â”œâ”€â”€ ğŸ“œ test{n}_{æ¨¡å‹}_results.csv              # æ¨¡å‹ç”¢ç”Ÿçš„å›ç­”çµæœ  
â”‚   â””â”€â”€ ğŸ“œ test{n}_{æ¨¡å‹}_evaluate_{eval_æ¨¡å‹}.csv # æ¨¡å‹å›ç­”èˆ‡é»ƒé‡‘ç­”æ¡ˆçš„è©•ä¼°å°ç…§è¡¨  
  
ğŸ“‚ data/  
â””â”€â”€ ğŸ“œ user/{user_name}/{user_name}.db # ä½¿ç”¨è€…å°æ‡‰çš„ QA è³‡æ–™ä¾†æº DB  
```

---

## ğŸ§  æŠ€è¡“èªªæ˜

- ä½¿ç”¨ `BGE-M3`, `Cosine Similarity` æœå°‹ç›¸é—œæ–‡ä»¶ (Chunks)
- å¯è¨­å®šä¸åŒè©•å¯©æ¨¡å‹ï¼ˆå¦‚ GPT-4oã€Gemma ç­‰ï¼‰ï¼Œ å¤šæ•¸æ±º(3æ¬¡)åˆ¤å®šå›ç­”æ˜¯å¦æ­£ç¢º
- å…·å‚™é™æµä¿è­·ï¼ˆæ¯å€‹æ¨¡å‹è©•ä¼°é–“å¯æš«åœæŒ‡å®šç§’æ•¸ï¼‰ 
- æµç¨‹åœ–  
![eval_workflow.png](eval_workflow.png) 
---

## ğŸ“Œ æ³¨æ„äº‹é …

- é ˆå…ˆè¨­å®š `.env` æª”æ¡ˆèˆ‡ `apis/llm_api.py`ï¼ˆ`api_base`ã€`api_key`ï¼‰ä»¥æŒ‡å®šæ¨¡å‹ä¾†æº
- è¼¸å…¥è³‡æ–™å»ºè­°ä½¿ç”¨çµæ§‹åŒ– PDF æˆ–å·²åˆ†æ®µæ–‡æœ¬ï¼Œèƒ½æé«˜å•ç­”ç”¢å‡ºæº–ç¢ºåº¦

---

## ğŸ‘©â€ğŸ’» æ¨¡çµ„è²¢ç»è€…

- æœ¬æ¨¡çµ„ç”± [Valerie Chen](mailto:valerie7331@gmail.com) è£½ä½œèˆ‡ç¶­è­·
