# run_llm_evaluation.py
import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import time
from export_data import RAGDataExporter
from gen_qa import AnswerGenerator
from eval_answer import AnswerEvaluator
from apis.llm_api import LLMAPI

test_num = 1

def run_step1_export():
    # æ­¥é©Ÿä¸€ï¼šå¾ SQLite è³‡æ–™åº«ä¸­åŒ¯å‡ºæ‰€æœ‰ RAG éç¨‹ä¸­çš„ Chunksï¼Œç”¢å‡º QAData_retrievedContent.csv (ä¸ä¸€å®šæœ‰GoldenChunk)
    db_path = "data/user/Guest/Guest.db"
    qa_retrieved_path = "mockdata/QAData_retrievedContent.csv"
    RAGDataExporter(db_path).export_to_csv(qa_retrieved_path)
    # æ‰‹å‹•åŠ å…¥ GoldenChunk (æœªå¯«ç¨‹å¼)
    # golden_chunk_path = "mockdata/QAData_goldenChunk.csv"


def run_step2_generate_answers():
    # æ­¥é©ŸäºŒï¼šæ ¹æ“š QA CSVï¼Œé‡å°æ¯å€‹æ¨¡å‹ç”Ÿæˆå›ç­”ä¸¦è¼¸å‡ºåˆ° mockdata/{æ¨¡å‹å}/{æ¨¡å‹å}_results.csv
    qa_csv_path = "mockdata/QAData_goldenChunk.csv"
    for llm_option in LLMAPI.llm_model_names.keys():
        output_path = f"mockdata/{llm_option}/test{test_num}_{llm_option}_results.csv"
        AnswerGenerator(llm_option).generate_answers(qa_csv_path, output_path)
        print(f"âœ… å®Œæˆæ¨¡å‹å›ç­”ç”Ÿæˆï¼š{llm_option}ï¼Œæš«åœ 5 åˆ†é˜é¿å…é™æµ")
        _countdown_sleep(300)
def run_step3_evaluate_answers():
    # æ­¥é©Ÿä¸‰ï¼šè®€å– QA æ¨™æº–ç­”æ¡ˆæª”èˆ‡æ¨¡å‹ç”¢ç”Ÿçš„å›ç­”ï¼Œä¸¦åŸ·è¡Œè©•ä¼°ï¼Œè¼¸å‡ºè©•ä¼°çµæœèˆ‡åˆ†æ•¸
    evaluator_llm = "Gemma3_27b"
    for llm_option in LLMAPI.llm_model_names.keys():
        llm_input_file = f"mockdata/{llm_option}/test{test_num}_{llm_option}_results.csv"
        output_path = f"mockdata/{llm_option}/test{test_num}_{llm_option}_evaluate_{evaluator_llm}.csv"
        if os.path.exists(llm_input_file):
            print(f"ğŸ” é–‹å§‹è©•ä¼°æ¨¡å‹å›ç­”ï¼š{llm_option}")
            AnswerEvaluator(
                correct_file="mockdata/QAData_1819.csv",    # æ­£ç¢ºç­”æ¡ˆ CSV æª”æ¡ˆï¼ˆå«æ¬„ä½ ID, Question, Answerï¼‰
                llm_input_file=llm_input_file,              # æ¨¡å‹ç”¢ç”Ÿçš„å›ç­”æª”æ¡ˆï¼ˆå« Answer_{llm_option} æ¬„ä½ï¼‰
                output_file=output_path,                    # è¼¸å‡ºè©•ä¼°çµæœçš„æª”æ¡ˆè·¯å¾‘
                mode="å…§éƒ¨LLM",                              # ä½¿ç”¨å…§éƒ¨æ¨¡å‹åšç‚ºè©•å¯©
                llm_option=llm_option,                      # ç•¶å‰è¦è©•ä¼°çš„æ¨¡å‹åç¨±
                evaluator_llm=evaluator_llm,                    # æ“”ä»»è©•å¯©çš„æ¨¡å‹ï¼ˆå¦‚ GPT-4o æˆ– Gemmaï¼‰
                evaluation_attempts=3                      # æ¯é¡Œé‡è¤‡è©•ä¼°æ¬¡æ•¸ï¼Œå–å¹³å‡
            ).evaluate_answers()

        else:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œç•¥éè©•ä¼°ï¼š{output_path}")

def _countdown_sleep(seconds):
    # å€’æ•¸ç­‰å¾…æ™‚é–“ï¼Œä¸¦å³æ™‚åœ¨åŒä¸€è¡Œæ›´æ–°æç¤ºï¼ˆé©åˆé™æµä¿è­·ï¼‰
    for remaining in range(seconds, 0, -1):
        mins, secs = divmod(remaining, 60)
        print(f"â³ å‰©é¤˜ç­‰å¾…æ™‚é–“ï¼š{mins:02d}:{secs:02d}", end='\r', flush=True)
        time.sleep(1)
    print("â³ å€’æ•¸çµæŸï¼     ")  # å¤šé¤˜ç©ºç™½é¿å…å‰é¢å­—æ®˜ç•™

if __name__ == "__main__":
    # Step 1ï¼šå¾ DB åŒ¯å‡º QA CSV
    # run_step1_export()

    # Step 2ï¼šé‡å°æ¯å€‹æ¨¡å‹ç”¢ç”Ÿå›ç­”
    # run_step2_generate_answers()

    # Step 3ï¼šå°ç”¢ç”Ÿçš„å›ç­”é€²è¡Œæ¨¡å‹è‡ªå‹•è©•ä¼°
    run_step3_evaluate_answers()
